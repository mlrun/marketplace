
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>huggingface_auto_trainer.huggingface_auto_trainer</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script data-url_root="../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<link href="../../genindex.html" rel="index" title="Index">
<link href="../../search.html" rel="search" title="Search">
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint single-page" id="site-navigation">
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
</div>
<div class="header-article__right">
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/mlrun/marketplace" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/mlrun/marketplace/issues/new?title=Issue%20on%20page%20%2F_modules/huggingface_auto_trainer/huggingface_auto_trainer.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1></h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<h1>Source code for huggingface_auto_trainer.huggingface_auto_trainer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">importlib</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">mlrun</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">peft</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">mlrun.artifacts.manager</span> <span class="kn">import</span> <span class="n">Artifact</span><span class="p">,</span> <span class="n">PlotlyArtifact</span>
<span class="kn">from</span> <span class="nn">mlrun.datastore</span> <span class="kn">import</span> <span class="n">is_store_uri</span>
<span class="kn">from</span> <span class="nn">mlrun.frameworks._common</span> <span class="kn">import</span> <span class="n">CommonTypes</span><span class="p">,</span> <span class="n">MLRunInterface</span>
<span class="kn">from</span> <span class="nn">mlrun.utils</span> <span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="p">(</span><span class="n">LoraConfig</span><span class="p">,</span> <span class="n">PeftModel</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span>
                  <span class="n">prepare_model_for_kbit_training</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">plotly</span> <span class="kn">import</span> <span class="n">graph_objects</span> <span class="k">as</span> <span class="n">go</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span>
                          <span class="n">BitsAndBytesConfig</span><span class="p">,</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">,</span>
                          <span class="n">PreTrainedModel</span><span class="p">,</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">,</span>
                          <span class="n">TrainerCallback</span><span class="p">,</span> <span class="n">TrainerControl</span><span class="p">,</span> <span class="n">TrainerState</span><span class="p">,</span>
                          <span class="n">TrainingArguments</span><span class="p">)</span>

<span class="n">supported_tasks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"question-answering"</span><span class="p">,</span>
    <span class="s2">"summarization"</span><span class="p">,</span>
    <span class="s2">"table-question-answering"</span><span class="p">,</span>
    <span class="s2">"text2text-generation"</span><span class="p">,</span>
    <span class="s2">"text-classification"</span><span class="p">,</span>
    <span class="s2">"sentiment-analysis"</span><span class="p">,</span>
    <span class="s2">"text-generation"</span><span class="p">,</span>
    <span class="s2">"token-classification"</span><span class="p">,</span>
    <span class="s2">"translation"</span><span class="p">,</span>
    <span class="s2">"translation_xx_to_yy"</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="ConfigKeys"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.ConfigKeys">[docs]</a><span class="k">class</span> <span class="nc">ConfigKeys</span><span class="p">:</span>
    <span class="n">deepspeed</span> <span class="o">=</span> <span class="s2">"deepspeed"</span>
    <span class="n">quantization</span> <span class="o">=</span> <span class="s2">"quantization"</span>
    <span class="n">lora</span> <span class="o">=</span> <span class="s2">"lora"</span>
    <span class="n">training</span> <span class="o">=</span> <span class="s2">"training"</span>
    <span class="n">tokenizer_pretrained</span> <span class="o">=</span> <span class="s2">"tokenizer_pretrained"</span>
    <span class="n">model_pretrained</span> <span class="o">=</span> <span class="s2">"model_pretrained"</span>
    <span class="n">data_collator</span> <span class="o">=</span> <span class="s2">"data_collator"</span></div>


<span class="c1"># ----------------------from MLRUN--------------------------------</span>
<div class="viewcode-block" id="HFTrainerMLRunInterface"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.HFTrainerMLRunInterface">[docs]</a><span class="k">class</span> <span class="nc">HFTrainerMLRunInterface</span><span class="p">(</span><span class="n">MLRunInterface</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This is temporary and will be built in mlrun 1.5.0</span>
<span class="sd">    Interface for adding MLRun features for tensorflow keras API.</span>
<span class="sd">    """</span>

    <span class="c1"># MLRuns context default name:</span>
    <span class="n">DEFAULT_CONTEXT_NAME</span> <span class="o">=</span> <span class="s2">"mlrun-huggingface"</span>

    <span class="c1"># Attributes to replace so the MLRun interface will be fully enabled.</span>
    <span class="n">_REPLACED_METHODS</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">"train"</span><span class="p">,</span>
        <span class="c1"># "evaluate"</span>
    <span class="p">]</span>

<div class="viewcode-block" id="HFTrainerMLRunInterface.add_interface"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.HFTrainerMLRunInterface.add_interface">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">add_interface</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">obj</span><span class="p">:</span> <span class="n">Trainer</span><span class="p">,</span>
        <span class="n">restoration</span><span class="p">:</span> <span class="n">CommonTypes</span><span class="o">.</span><span class="n">MLRunInterfaceRestorationType</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HFTrainerMLRunInterface</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">add_interface</span><span class="p">(</span>
            <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span> <span class="n">restoration</span><span class="o">=</span><span class="n">restoration</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="HFTrainerMLRunInterface.mlrun_train"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.HFTrainerMLRunInterface.mlrun_train">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">mlrun_train</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">Trainer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># Restore the evaluation method as `train` will use it:</span>
            <span class="c1"># cls._restore_attribute(obj=self, attribute_name="evaluate")</span>

            <span class="c1"># Call the original fit method:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_train</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="c1"># Replace the evaluation method again:</span>
            <span class="c1"># cls._replace_function(obj=self, function_name="evaluate")</span>

            <span class="k">return</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">wrapper</span></div></div>


<div class="viewcode-block" id="MLRunCallback"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback">[docs]</a><span class="k">class</span> <span class="nc">MLRunCallback</span><span class="p">(</span><span class="n">TrainerCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This is temporary and will be built in mlrun 1.5.0</span>
<span class="sd">    Callback for collecting logs during training / evaluation of the `Trainer` API.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">context</span><span class="p">:</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">MLClientCtx</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"model"</span><span class="p">,</span>
        <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extra_data</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Store the configurations:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">context</span>
            <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">get_or_create_ctx</span><span class="p">(</span><span class="s2">"./mlrun-huggingface"</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tag</span> <span class="o">=</span> <span class="n">tag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extra_data</span> <span class="o">=</span> <span class="n">extra_data</span> <span class="k">if</span> <span class="n">extra_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="c1"># Set up the logging mode:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_training</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metric_scores</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_artifacts</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Artifact</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="MLRunCallback.on_epoch_begin"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.on_epoch_begin">[docs]</a>    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">TrainingArguments</span><span class="p">,</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">TrainerState</span><span class="p">,</span>
        <span class="n">control</span><span class="p">:</span> <span class="n">TrainerControl</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="o">.</span><span class="n">is_world_process_zero</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span></div>

<div class="viewcode-block" id="MLRunCallback.on_epoch_end"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.on_epoch_end">[docs]</a>    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">TrainingArguments</span><span class="p">,</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">TrainerState</span><span class="p">,</span>
        <span class="n">control</span><span class="p">:</span> <span class="n">TrainerControl</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="o">.</span><span class="n">is_world_process_zero</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">()</span></div>

<div class="viewcode-block" id="MLRunCallback.on_log"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.on_log">[docs]</a>    <span class="k">def</span> <span class="nf">on_log</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">TrainingArguments</span><span class="p">,</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">TrainerState</span><span class="p">,</span>
        <span class="n">control</span><span class="p">:</span> <span class="n">TrainerControl</span><span class="p">,</span>
        <span class="n">logs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="o">.</span><span class="n">is_world_process_zero</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">recent_logs</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">log_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="n">recent_logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"epoch"</span><span class="p">)</span>
        <span class="n">current_step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">recent_logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"step"</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">current_step</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_score</span> <span class="ow">in</span> <span class="n">recent_logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">metric_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"train_"</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">metric_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"train_"</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_scores</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_metric_scores</span><span class="p">[</span><span class="n">metric_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">metric_score</span><span class="p">]</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">metric_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_scores</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_metric_scores</span><span class="p">[</span><span class="n">metric_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_metric_scores</span><span class="p">[</span><span class="n">metric_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_score</span><span class="p">)</span></div>

<div class="viewcode-block" id="MLRunCallback.on_train_begin"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.on_train_begin">[docs]</a>    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">TrainingArguments</span><span class="p">,</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">TrainerState</span><span class="p">,</span>
        <span class="n">control</span><span class="p">:</span> <span class="n">TrainerControl</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="o">.</span><span class="n">is_world_process_zero</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_training</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="MLRunCallback.on_train_end"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.on_train_end">[docs]</a>    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">TrainingArguments</span><span class="p">,</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">TrainerState</span><span class="p">,</span>
        <span class="n">control</span><span class="p">:</span> <span class="n">TrainerControl</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">PreTrainedModel</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="o">.</span><span class="n">is_world_process_zero</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">()</span></div>

<div class="viewcode-block" id="MLRunCallback.on_evaluate"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.on_evaluate">[docs]</a>    <span class="k">def</span> <span class="nf">on_evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">TrainingArguments</span><span class="p">,</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">TrainerState</span><span class="p">,</span>
        <span class="n">control</span><span class="p">:</span> <span class="n">TrainerControl</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">state</span><span class="o">.</span><span class="n">is_world_process_zero</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_training</span><span class="p">:</span>
            <span class="k">return</span></div>

<div class="viewcode-block" id="MLRunCallback.log_metrics"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.log_metrics">[docs]</a>    <span class="k">def</span> <span class="nf">log_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_scores</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metric_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">log_result</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">metric_scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric_scores</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_metric_plot</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">metric_scores</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">commit</span><span class="p">(</span><span class="n">completed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="MLRunCallback.log_metric_plot"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.MLRunCallback.log_metric_plot">[docs]</a>    <span class="k">def</span> <span class="nf">log_metric_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">scores</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]):</span>
        <span class="c1"># Initialize a plotly figure:</span>
        <span class="n">metric_figure</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>

        <span class="c1"># Add titles:</span>
        <span class="n">metric_figure</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
            <span class="n">title</span><span class="o">=</span><span class="n">name</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"_"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">),</span>
            <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">"Samples"</span><span class="p">,</span>
            <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">"Scores"</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Draw:</span>
        <span class="n">metric_figure</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
            <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)),</span> <span class="n">y</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"lines"</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Create the plotly artifact:</span>
        <span class="n">artifact_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_plot"</span>
        <span class="n">artifact</span> <span class="o">=</span> <span class="n">PlotlyArtifact</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">artifact_name</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">metric_figure</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_artifacts</span><span class="p">[</span><span class="n">artifact_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">artifact</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="apply_mlrun"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.apply_mlrun">[docs]</a><span class="k">def</span> <span class="nf">apply_mlrun</span><span class="p">(</span>
    <span class="n">trainer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span>
    <span class="n">context</span><span class="p">:</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">MLClientCtx</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">auto_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_data</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This is temporary and will be built in mlrun 1.5.0</span>
<span class="sd">    """</span>
    <span class="c1"># Get parameters defaults:</span>
    <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">get_or_create_ctx</span><span class="p">(</span><span class="n">HFTrainerMLRunInterface</span><span class="o">.</span><span class="n">DEFAULT_CONTEXT_NAME</span><span class="p">)</span>

    <span class="n">HFTrainerMLRunInterface</span><span class="o">.</span><span class="n">add_interface</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">auto_log</span><span class="p">:</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span>
            <span class="n">MLRunCallback</span><span class="p">(</span>
                <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">,</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">extra_data</span><span class="o">=</span><span class="n">extra_data</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span></div>


<span class="c1"># ----------------------end from MLRUN--------------------------------</span>


<span class="k">def</span> <span class="nf">_print_trainable_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Prints the number of trainable parameters in the model.</span>
<span class="sd">    """</span>
    <span class="n">trainable_params</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">all_param</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="n">all_param</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
            <span class="n">trainable_params</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">"trainable params: </span><span class="si">{</span><span class="n">trainable_params</span><span class="si">}</span><span class="s2"> || all params: </span><span class="si">{</span><span class="n">all_param</span><span class="si">}</span><span class="s2"> || trainable%:"</span>
        <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">trainable_params</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">all_param</span><span class="si">}</span><span class="s2">"</span>
    <span class="p">)</span>


<span class="c1"># default configs</span>
<span class="c1"># will be used if user provides "True" with config name as input</span>
<span class="n">QUANTIZATION_CONFIG</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span>
    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">"nf4"</span><span class="p">,</span>
    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">LORA_CONFIG</span> <span class="o">=</span> <span class="n">peft</span><span class="o">.</span><span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">"query_key_value"</span><span class="p">],</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="s2">"none"</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="s2">"CAUSAL_LM"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">DEEPSPEED_CONFIG</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"train_micro_batch_size_per_gpu"</span><span class="p">:</span> <span class="s2">"auto"</span><span class="p">,</span>
    <span class="s2">"fp16"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"enabled"</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
    <span class="s2">"autotuning"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"enabled"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">"arg_mappings"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"train_micro_batch_size_per_gpu"</span><span class="p">:</span> <span class="s2">"--per_device_train_batch_size"</span><span class="p">,</span>
            <span class="s2">"gradient_accumulation_steps "</span><span class="p">:</span> <span class="s2">"--gradient_accumulation_steps"</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="s2">"zero_optimization"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"stage"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">_update_config</span><span class="p">(</span><span class="n">src</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">dst</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    update configs according to user, this way the user can add/modify values in default configs for e.g.</span>

<span class="sd">    goes over all configs and corresponding prefixes, collect all the keys from the given dict that start</span>
<span class="sd">     with the prefix and add them to appropriate config</span>

<span class="sd">    :param src: dict of all candidate values to update dict.</span>
<span class="sd">    :param dst: dict containing all configs to update.</span>
<span class="sd">    """</span>

    <span class="k">for</span> <span class="n">config_name</span><span class="p">,</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">dst</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

        <span class="c1"># If given True we use default dict</span>
        <span class="c1"># Can also be False or a config dict given from user, so we check specifically fo True</span>
        <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">config_name</span> <span class="o">==</span> <span class="s2">"quantization"</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">QUANTIZATION_CONFIG</span>

        <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">config_name</span> <span class="o">==</span> <span class="s2">"lora"</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">LORA_CONFIG</span>

        <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">config_name</span> <span class="o">==</span> <span class="s2">"deepspeed"</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">DEEPSPEED_CONFIG</span>

        <span class="c1"># in some cases we can get a boolean value, in that case no need to look for args</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="n">config</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">src</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">config_name</span><span class="p">):</span>
                    <span class="n">config</span><span class="p">[</span><span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">_"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)]</span> <span class="o">=</span> <span class="n">val</span>

        <span class="c1"># update by config name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">src</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">config_name</span><span class="p">):</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">_"</span><span class="p">,</span> <span class="s2">""</span><span class="p">),</span> <span class="n">val</span><span class="p">)</span>

        <span class="n">dst</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">config_name</span><span class="p">:</span> <span class="n">config</span><span class="p">})</span>


<span class="k">def</span> <span class="nf">_get_class_object</span><span class="p">(</span><span class="n">class_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">type</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    given a full class name, this function returns the correct class</span>

<span class="sd">    :param class_path: a full class name (ex. 'transformers.AutoModelForCausalLM')</span>

<span class="sd">    :return the wanted class object</span>
<span class="sd">    """</span>
    <span class="n">module_path</span><span class="p">,</span> <span class="n">class_name</span> <span class="o">=</span> <span class="n">class_path</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">"."</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">module_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">class_name</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_set_model_and_tokenizer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">framework</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">lora_config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">use_cuda</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">tokenizer_pretrained_config</span><span class="p">,</span>
    <span class="n">model_pretrained_config</span><span class="p">,</span>
    <span class="n">device_map</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    get the correct model and tokenizer according to given user inputs</span>

<span class="sd">    :param model: a tuple containing model name and class, or str with model name or path</span>
<span class="sd">    :param tokenizer: a tuple containing tokenizer name and class, or str with tokenizer name or path</span>
<span class="sd">    :param task: a supported nlp task, used to choose model if not provided</span>
<span class="sd">    :param framework: pt or tf</span>
<span class="sd">    :param lora_config: lora config or None, to load model in appropriate way</span>
<span class="sd">    :param quantization_config: quantization config or None, to load model in appropriate way</span>
<span class="sd">    :param use_cuda: use gpu or not</span>
<span class="sd">    :param tokenizer_pretrained_config: config to load the pretrained tokenizer</span>
<span class="sd">    :param model_pretrained_config: config to load the pretrained model</span>
<span class="sd">    :param device_map: a device map for model training if using number of gpu's</span>

<span class="sd">    :returns: model and tokenizer</span>
<span class="sd">    """</span>
    <span class="c1"># if task is not supported and no model was given we can't choose one</span>
    <span class="k">if</span> <span class="n">task</span> <span class="ow">and</span> <span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_tasks</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">model</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"unsupported task option chosen"</span><span class="p">)</span>
        <span class="k">raise</span>

    <span class="c1"># load model from store</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_store_uri</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="k">pass</span>
        <span class="c1"># TODO: load both model and tokenizer and return, need guy's help</span>

    <span class="c1"># if it's a tuple them we assume it contains of both name and class</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">model_name</span><span class="p">,</span> <span class="n">model_class</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">model_class</span> <span class="o">=</span> <span class="n">_get_class_object</span><span class="p">(</span><span class="n">model_class</span><span class="p">)</span>

    <span class="c1"># in the case we don't get the model class we need the task in order to choose the correct model</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"task must be chosen in order to determine the correct model"</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">"this function requires either a supported task or a model and model class to be chosen"</span>
            <span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">available_classes</span><span class="p">,</span> <span class="n">task_options</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">check_task</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span>

        <span class="c1"># if model is not given, we take the default model for the given task</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_name</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">get_default_model_and_revision</span><span class="p">(</span>
                <span class="n">available_classes</span><span class="p">,</span> <span class="n">framework</span><span class="p">,</span> <span class="n">task_options</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">available_classes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">framework</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">()):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">"given task's default model is not supported in specified framework"</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">"this function requires either a supported task or a model and model class to be chosen"</span>
            <span class="p">)</span>

        <span class="n">model_class</span> <span class="o">=</span> <span class="n">available_classes</span><span class="p">[</span><span class="n">framework</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># load the pretrained model</span>
    <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
        <span class="n">device_map</span> <span class="o">=</span> <span class="n">device_map</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">device_map</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_name</span><span class="p">,</span>
        <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span><span class="p">,</span>
        <span class="n">device_map</span><span class="o">=</span><span class="n">device_map</span><span class="p">,</span>
        <span class="o">**</span><span class="n">model_pretrained_config</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># If quantization config is given we will load a quantized model, if not a regular one</span>
    <span class="k">if</span> <span class="n">quantization_config</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">peft</span><span class="o">.</span><span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># If lora config was given we want to do lora fine tune, we update model here</span>
    <span class="k">if</span> <span class="n">lora_config</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">peft</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>

    <span class="c1"># if not specified we choose the default tokenizer that corresponding to the model</span>
    <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">tokenizer_name</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">tokenizer_class</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span>

    <span class="c1"># if it's not a str then it's a tuple of both name and class</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tokenizer_name</span><span class="p">,</span> <span class="n">tokenizer_class</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">tokenizer_class</span> <span class="o">=</span> <span class="n">_get_class_object</span><span class="p">(</span><span class="n">tokenizer_class</span><span class="p">)</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">tokenizer_name</span><span class="p">,</span> <span class="o">**</span><span class="n">tokenizer_pretrained_config</span>
    <span class="p">)</span>

    <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

    <span class="k">return</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>


<span class="k">def</span> <span class="nf">_dataset_loader</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">is_train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    loads the specific dataset provided by the user</span>

<span class="sd">    :param dataset: name or path of dataset to load</span>
<span class="sd">    :param is_train: bool that indicates the purpose of the dataset</span>
<span class="sd">    :param kwargs: other kwargs for loading the dataset</span>

<span class="sd">    :returns: loaded dataset</span>
<span class="sd">    """</span>
    <span class="c1"># if split in kwargs then the user decides how to split the dataset</span>
    <span class="k">if</span> <span class="s2">"split"</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># if it's a dataset for train we split with train</span>
    <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">"train"</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># if it's eval dataset, then a lot of names are acceptable for the set and we check all of them</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">"test"</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"test"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="s2">"eval"</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="s2">"validation"</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"validation"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_prepare_dataset</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">train_load_dataset_kwargs</span><span class="p">,</span>
    <span class="n">eval_load_dataset_kwargs</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">dataset_columns_to_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dataset</span><span class="p">,</span> <span class="kc">None</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Loads the train and eval datasets (if provided) passes them through the tokenizer and</span>
<span class="sd">    returns them ready to use in training</span>

<span class="sd">    :param train_dataset: the name or path to the train dataset</span>
<span class="sd">    :param eval_dataset: the name or path to the eval dataset</span>
<span class="sd">    :param dataset_columns_to_train: which columns to pass to the model as inputs</span>
<span class="sd">                                        (need to pass through the tokenizer first)</span>
<span class="sd">    :param train_load_dataset_kwargs: kwargs for dataset loading</span>
<span class="sd">    :param eval_load_dataset_kwargs: kwargs for dataset loading</span>
<span class="sd">    :param tokenizer: the tokenizer to pass the data through</span>

<span class="sd">    :returns: tokenized datasets</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">:</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

    <span class="c1"># we take col name/s in a list for easy generalization</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset_columns_to_train</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">dataset_columns_to_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset_columns_to_train</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">datastore</span><span class="o">.</span><span class="n">DataItem</span><span class="p">):</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">as_df</span><span class="p">())</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span>
                    <span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset_columns_to_train</span><span class="p">],</span>
                    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Load datasets</span>
    <span class="c1"># if provided two paths/names we load each separately using designated func</span>
    <span class="k">if</span> <span class="n">eval_dataset</span><span class="p">:</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">_dataset_loader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">train_load_dataset_kwargs</span>
        <span class="p">)</span>
        <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">_dataset_loader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">eval_load_dataset_kwargs</span>
        <span class="p">)</span>

    <span class="c1"># if only on path is given then we must check if it contains both dataset or if only one should be used</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">train_load_dataset_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">"train"</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"train"</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">"test"</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
                <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"test"</span><span class="p">)</span>
            <span class="k">elif</span> <span class="s2">"eval"</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
                <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">)</span>
            <span class="k">elif</span> <span class="s2">"validation"</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
                <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"validation"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># only train dataset given, tokenize and return it</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                        <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span>
                            <span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset_columns_to_train</span><span class="p">],</span>
                            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="kc">None</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"train dataset is mandatory"</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">"no train dataset found in given dataset"</span><span class="p">)</span>

    <span class="c1"># Tokenize the data so the model can understand it</span>
    <span class="n">tokenized_train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset_columns_to_train</span><span class="p">],</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">tokenized_eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset_columns_to_train</span><span class="p">],</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">tokenized_train_dataset</span><span class="p">,</span> <span class="n">tokenized_eval_dataset</span>


<div class="viewcode-block" id="finetune_llm"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.finetune_llm">[docs]</a><span class="k">def</span> <span class="nf">finetune_llm</span><span class="p">(</span>
    <span class="n">context</span><span class="p">:</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">MLClientCtx</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">datastore</span><span class="o">.</span><span class="n">DataItem</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_load_dataset_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">eval_load_dataset_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">dataset_columns_to_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"text"</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">"huggingface-model"</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">deepspeed_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">lora_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">training_config</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">model_pretrained_config</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">tokenizer_pretrained_config</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">data_collator_config</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"text-generation"</span><span class="p">,</span>
    <span class="n">use_cuda</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">framework</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"pt"</span><span class="p">,</span>
    <span class="n">device_map</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"auto"</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Fine-tunes a Language Model (LLM) on a specific task using the provided dataset.</span>
<span class="sd">     The function takes various configuration parameters to customize the training process</span>
<span class="sd">     and adapt the model to specific tasks using a provided dataset.</span>

<span class="sd">    :param context: mlrun context in order to log trained model</span>
<span class="sd">    :param dataset_columns_to_train: which columns to pass to the model as inputs</span>
<span class="sd">    :param eval_load_dataset_kwargs: kwargs for dataset loading</span>
<span class="sd">    :param train_load_dataset_kwargs: kwargs for dataset loading</span>
<span class="sd">    :param framework: pt ot tf</span>
<span class="sd">    :param use_cuda: use gpu or not</span>
<span class="sd">    :param tokenizer_pretrained_config: config to load the pretrained tokenizer</span>
<span class="sd">    :param model_pretrained_config: config to load the pretrained model</span>
<span class="sd">    :param tokenizer: a tuple containing tokenizer name and class, or str with tokenizer name or path</span>
<span class="sd">    :param model: a tuple containing model name and class, or str with model name or path</span>
<span class="sd">    :param train_dataset: The train dataset used for fine-tuning the language model.</span>
<span class="sd">    :param eval_dataset: The eval dataset used for evaluate the language model during training.</span>
<span class="sd">    :param deepspeed_config: Configuration options for DeepSpeed (optional).</span>
<span class="sd">    :param quantization_config: Configuration options for model quantization (optional).</span>
<span class="sd">    :param lora_config: Configuration options for Low-Rank Approximation (LoRA) (optional).</span>
<span class="sd">    :param training_config: Configuration options specific to the fine-tuning training process (optional).</span>
<span class="sd">    :param data_collator_config: Configuration options for data collation during training (optional).</span>
<span class="sd">    :param task: A description of the specific task the model is being fine-tuned for.</span>
<span class="sd">    :param kwargs: Additional keyword arguments.</span>
<span class="sd">    """</span>

    <span class="c1"># TODO: match forward.keyword to dataset.keyword - check if relevant in new design</span>
    <span class="c1"># TODO: add warning for label, and add option to modify dataset col names - check if relevant in new design</span>

    <span class="c1"># Look for updates to configs given in kwargs</span>
    <span class="n">configs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">ConfigKeys</span><span class="o">.</span><span class="n">deepspeed</span><span class="p">:</span> <span class="n">deepspeed_config</span><span class="p">,</span>
        <span class="n">ConfigKeys</span><span class="o">.</span><span class="n">quantization</span><span class="p">:</span> <span class="n">quantization_config</span><span class="p">,</span>
        <span class="n">ConfigKeys</span><span class="o">.</span><span class="n">lora</span><span class="p">:</span> <span class="n">lora_config</span><span class="p">,</span>
        <span class="n">ConfigKeys</span><span class="o">.</span><span class="n">training</span><span class="p">:</span> <span class="n">training_config</span><span class="p">,</span>
        <span class="n">ConfigKeys</span><span class="o">.</span><span class="n">model_pretrained</span><span class="p">:</span> <span class="n">model_pretrained_config</span><span class="p">,</span>
        <span class="n">ConfigKeys</span><span class="o">.</span><span class="n">tokenizer_pretrained</span><span class="p">:</span> <span class="n">tokenizer_pretrained_config</span><span class="p">,</span>
        <span class="n">ConfigKeys</span><span class="o">.</span><span class="n">data_collator</span><span class="p">:</span> <span class="n">data_collator_config</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">_update_config</span><span class="p">(</span><span class="n">dst</span><span class="o">=</span><span class="n">configs</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># check gpu permission and availability</span>
    <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="c1"># Clean gpu cache</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"'use_cuda' is set to True, but no cuda device is available"</span><span class="p">)</span>

    <span class="c1"># get model and tokenizer</span>
    <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">_set_model_and_tokenizer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
        <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">,</span>
        <span class="n">lora_config</span><span class="o">=</span><span class="n">configs</span><span class="p">[</span><span class="n">ConfigKeys</span><span class="o">.</span><span class="n">lora</span><span class="p">],</span>
        <span class="n">quantization_config</span><span class="o">=</span><span class="n">configs</span><span class="p">[</span><span class="n">ConfigKeys</span><span class="o">.</span><span class="n">quantization</span><span class="p">],</span>
        <span class="n">use_cuda</span><span class="o">=</span><span class="n">use_cuda</span><span class="p">,</span>
        <span class="n">tokenizer_pretrained_config</span><span class="o">=</span><span class="n">tokenizer_pretrained_config</span><span class="p">,</span>
        <span class="n">model_pretrained_config</span><span class="o">=</span><span class="n">configs</span><span class="p">[</span><span class="n">ConfigKeys</span><span class="o">.</span><span class="n">model_pretrained</span><span class="p">],</span>
        <span class="n">device_map</span><span class="o">=</span><span class="n">device_map</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Load datasets</span>
    <span class="n">tokenized_train</span><span class="p">,</span> <span class="n">tokenized_eval</span> <span class="o">=</span> <span class="n">_prepare_dataset</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
        <span class="n">train_load_dataset_kwargs</span><span class="o">=</span><span class="n">train_load_dataset_kwargs</span><span class="p">,</span>
        <span class="n">eval_load_dataset_kwargs</span><span class="o">=</span><span class="n">eval_load_dataset_kwargs</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">dataset_columns_to_train</span><span class="o">=</span><span class="n">dataset_columns_to_train</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Initialize the data collator for the trainer to use in order to create batches of data</span>
    <span class="n">data_collator</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">data_collator_config</span>
    <span class="p">)</span>

    <span class="c1"># Initialize training kwargs from user kwargs:</span>
    <span class="n">train_kwargs</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">ConfigKeys</span><span class="o">.</span><span class="n">training</span><span class="p">]</span>

    <span class="c1"># If deepspeed config given we add it to training kwargs</span>
    <span class="k">if</span> <span class="n">configs</span><span class="p">[</span><span class="n">ConfigKeys</span><span class="o">.</span><span class="n">deepspeed</span><span class="p">]:</span>
        <span class="n">train_kwargs</span><span class="p">[</span><span class="s2">"deepspeed"</span><span class="p">]</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">ConfigKeys</span><span class="o">.</span><span class="n">deepspeed</span><span class="p">]</span>

    <span class="c1"># Take a look at the trainable parameters in the model</span>
    <span class="n">_print_trainable_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># Preparing training arguments:</span>
    <span class="n">training_args</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">(),</span>
        <span class="o">**</span><span class="n">train_kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized_train</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tokenized_eval</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">apply_mlrun</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">False</span>  <span class="c1"># silence the warnings. Please re-enable for inference!</span>
    <span class="p">)</span>

    <span class="c1"># Apply training with evaluation:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"training '</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">'"</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">temp_directory</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span><span class="o">.</span><span class="n">name</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">temp_directory</span><span class="p">)</span>

    <span class="c1"># Zip the model directory:</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">make_archive</span><span class="p">(</span>
        <span class="n">base_name</span><span class="o">=</span><span class="s2">"model"</span><span class="p">,</span>
        <span class="nb">format</span><span class="o">=</span><span class="s2">"zip"</span><span class="p">,</span>
        <span class="n">root_dir</span><span class="o">=</span><span class="n">temp_directory</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Log the model:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">key</span><span class="o">=</span><span class="s2">"model"</span><span class="p">,</span>
        <span class="n">db_key</span><span class="o">=</span><span class="n">model_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">model_file</span><span class="o">=</span><span class="s2">"model.zip"</span><span class="p">,</span>
        <span class="n">tag</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span>
        <span class="n">framework</span><span class="o">=</span><span class="s2">"Hugging Face"</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="evaluate"><a class="viewcode-back" href="documentation.html#huggingface_auto_trainer.huggingface_auto_trainer.evaluate">[docs]</a><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">context</span><span class="p">,</span>
    <span class="n">model_path</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tokenizer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Evaluating the model using perplexity, for more information visit:</span>
<span class="sd">    https://huggingface.co/docs/transformers/perplexity</span>

<span class="sd">    :param context:     mlrun context</span>
<span class="sd">    :param model_path:  path to the model directory</span>
<span class="sd">    :param data:        the data to evaluate the model</span>
<span class="sd">    :param model_name:  name of base model</span>
<span class="sd">    :param tokenizer_name: name of base tokenizer</span>
<span class="sd">    """</span>
    <span class="c1"># Get the model artifact and file:</span>
    <span class="p">(</span>
        <span class="n">model_file</span><span class="p">,</span>
        <span class="n">model_artifact</span><span class="p">,</span>
        <span class="n">extra_data</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">artifacts</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

    <span class="c1"># Read the name:</span>
    <span class="n">_model_name</span> <span class="o">=</span> <span class="n">model_artifact</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">db_key</span>

    <span class="c1"># Extract logged model files:</span>
    <span class="n">model_directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">model_file</span><span class="p">),</span> <span class="n">_model_name</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_file</span><span class="p">:</span>
        <span class="n">zip_file</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">model_directory</span><span class="p">)</span>

    <span class="c1"># Loading the saved pretrained tokenizer and model:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer_name</span><span class="p">)</span>
    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_name</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">"cuda:0"</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">PeftModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_directory</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">encodings</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"text"</span><span class="p">][:</span><span class="mi">5</span><span class="p">]),</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>

    <span class="n">max_length</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">encodings</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">nlls</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_end_loc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">begin_loc</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">end_loc</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">begin_loc</span> <span class="o">+</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
        <span class="n">trg_len</span> <span class="o">=</span> <span class="n">end_loc</span> <span class="o">-</span> <span class="n">prev_end_loc</span>  <span class="c1"># may be different from stride on last loop</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">encodings</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="n">begin_loc</span><span class="p">:</span><span class="n">end_loc</span><span class="p">]</span>
        <span class="n">target_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">target_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="n">trg_len</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">labels</span><span class="o">=</span><span class="n">target_ids</span><span class="p">)</span>

            <span class="c1"># loss is calculated using CrossEntropyLoss which averages over valid labels</span>
            <span class="c1"># N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels</span>
            <span class="c1"># to the left by 1.</span>
            <span class="n">neg_log_likelihood</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>

        <span class="n">nlls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neg_log_likelihood</span><span class="p">)</span>

        <span class="n">prev_end_loc</span> <span class="o">=</span> <span class="n">end_loc</span>
        <span class="k">if</span> <span class="n">end_loc</span> <span class="o">==</span> <span class="n">seq_len</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="n">ppl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">nlls</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">context</span><span class="o">.</span><span class="n">log_result</span><span class="p">(</span><span class="s2">"perplexity"</span><span class="p">,</span> <span class="n">ppl</span><span class="p">)</span></div>
</pre></div>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
       Copyright .<br/>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>