{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BERT Based Sentiment Analysis Model Server**\n",
    "The model used here, was trained with the concept of transfer learning  i.e. taking `huggingface` transformers pretrained `BERT` model and further training it on a custom dataset of reviews.<br> this yields a sentiment analysis model based on the prior knowledge of BERT. <br>\n",
    "The model server is given a list of texts and outputs a list of labels corresponding to its prediction.<br>\n",
    "The labels express the sentiment of the writer towards the topic of the text:<br>\n",
    "0 for negative sentiment, 1 for neutral and 2 for positive.<br>\n",
    "This function is part of the [stock-analysis demo.](https://github.com/mlrun/demos/tree/master/stock-analysis)\n",
    "\n",
    "The model file (~430 MB), can be downloaded to your local environment from: https://iguazio-sample-data.s3.amazonaws.com/models/model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps**\n",
    "1. [Setup function parameters](#Setup-function-parameters)\n",
    "2. [Importing the function](#Importing-the-function)\n",
    "3. [Testing the function locally](#Testing-the-function-locally)\n",
    "4. [Testing the function remotely](#Testing-the-function-remotely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following packages are required, make sure to install\n",
    "# !pip install transformers==3.0.2\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup function parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up models path\n",
    "model_location = 'https://iguazio-sample-data.s3.amazonaws.com/models/model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "mlrun.set_environment(project='function-marketplace')\n",
    "\n",
    "fn = mlrun.import_function('hub://sentiment_analysis_serving')\n",
    "fn.apply(mlrun.auto_mount())\n",
    "fn.add_model('mymodel', model_path=model_location, class_name='SentimentClassifierServing')\n",
    "\n",
    "# Manually specifying needed packages \n",
    "fn.spec.build.commands = ['pip install transformers==3.0.2', 'pip install torch']\n",
    "\n",
    "# Loading the model takes long times, so extanding timeout so deployment wont fail.\n",
    "fn.spec.readiness_timeout = 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the function locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-17 06:55:26,964 [info] model mymodel was loaded\n",
      "> 2021-10-17 06:55:26,969 [info] Initializing endpoint records\n",
      "> 2021-10-17 06:55:26,991 [info] Loaded ['mymodel']\n"
     ]
    }
   ],
   "source": [
    "# When mocking, class has to be present\n",
    "from sentiment_analysis_serving import *\n",
    "\n",
    "# create an emulator (mock server) from the function configuration)\n",
    "server = fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '40270df2843c4afbae53afb94b58664b',\n",
       " 'model_name': 'mymodel',\n",
       " 'outputs': [2, 2, 0, 0, 2]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KFServing protocol event\n",
    "event_data = {'inputs' : [# Here we test a pretty straightforward example for positive sentiment.\n",
    "                          'I had a pleasure to work with such dedicated team. Looking forward to cooperate with each and every one of them again.',\n",
    "                          'This app is amazingly good.', \n",
    "                          # Here we test a pretty straightforward example for bad sentiment.\n",
    "                          'The new design is awful!',\n",
    "                          'the mobile app can be really glitchy and is definitely not user friendly',\n",
    "                          # arguably harder due to misleading words that express, on their own, an opposite sentiment comparing to the full text.\n",
    "                          'As much as I hate to admit it, the new added feature is surprisingly user friendly.']}\n",
    "\n",
    "response = server.test(\"/v2/models/mymodel/predict\", body=event_data)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the function remotely**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-17 07:00:33,444 [info] Starting remote function deploy\n",
      "2021-10-17 07:00:33  (info) Deploying function\n",
      "2021-10-17 07:00:33  (info) Building\n",
      "2021-10-17 07:00:33  (info) Staging files and preparing base images\n",
      "2021-10-17 07:00:33  (info) Building processor image\n",
      "2021-10-17 07:00:34  (info) Build complete\n",
      "2021-10-17 07:02:24  (info) Function deploy complete\n",
      "> 2021-10-17 07:02:25,851 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-default-sentiment-analysis-serving.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['default-tenant.app.dev39.lab.iguazeng.com:31010']}\n"
     ]
    }
   ],
   "source": [
    "address = fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": \"40270df2843c4afbae53afb94b58664b\", \"model_name\": \"mymodel\", \"outputs\": [2, 2, 0, 0, 2]}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# using requests to predict\n",
    "response = requests.put(address + \"/v2/models/mymodel/predict\", json=json.dumps(event_data))\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BERT-Based-Sentiment-Analysis-Model-Server)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
