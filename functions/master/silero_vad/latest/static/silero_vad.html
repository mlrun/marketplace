
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>silero_vad.silero_vad</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script data-url_root="../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<link href="../../genindex.html" rel="index" title="Index">
<link href="../../search.html" rel="search" title="Search">
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint single-page" id="site-navigation">
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
</div>
<div class="header-article__right">
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/mlrun/marketplace" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/mlrun/marketplace/issues/new?title=Issue%20on%20page%20%2F_modules/silero_vad/silero_vad.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1></h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<h1>Source code for silero_vad.silero_vad</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2024 Iguazio</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#   http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Process</span><span class="p">,</span> <span class="n">Queue</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">types</span> <span class="kn">import</span> <span class="n">FunctionType</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>


<div class="viewcode-block" id="BaseTask"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.BaseTask">[docs]</a><span class="k">class</span> <span class="nc">BaseTask</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A base class for a task to complete after VAD.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_file</span><span class="p">:</span> <span class="n">Path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initialize the base task.</span>

<span class="sd">        :param audio_file: The audio file assigned to the task.</span>
<span class="sd">        """</span>
        <span class="c1"># Store the audio file:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_audio_file</span> <span class="o">=</span> <span class="n">audio_file</span>

        <span class="c1"># Prepare the result:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_result</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">audio_file</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Get the audio file of the task.</span>

<span class="sd">        :returns: The audio file of the task.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_audio_file</span>

<div class="viewcode-block" id="BaseTask.do_task"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.BaseTask.do_task">[docs]</a>    <span class="k">def</span> <span class="nf">do_task</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">speech_timestamps</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]]</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Do the task on the given speech timestamps. The base task will simply save the speech timestamps as the result.</span>

<span class="sd">        :param speech_timestamps: The speech timestamps to do the task on as outputted from the VAD.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_result</span> <span class="o">=</span> <span class="n">speech_timestamps</span></div>

<div class="viewcode-block" id="BaseTask.get_result"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.BaseTask.get_result">[docs]</a>    <span class="k">def</span> <span class="nf">get_result</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Get the result of the task. A tuple of the audio file name and the result.</span>

<span class="sd">        :returns: The result of the task.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_audio_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_result</span></div>

<div class="viewcode-block" id="BaseTask.to_tuple"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.BaseTask.to_tuple">[docs]</a>    <span class="k">def</span> <span class="nf">to_tuple</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Convert the task to a tuple to reconstruct it later (used for multiprocessing to pass in queue).</span>

<span class="sd">        :returns: The converted task.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="p">{</span><span class="s2">"audio_file"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_audio_file</span><span class="p">}</span></div></div>


<div class="viewcode-block" id="SpeechDiarizationTask"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.SpeechDiarizationTask">[docs]</a><span class="k">class</span> <span class="nc">SpeechDiarizationTask</span><span class="p">(</span><span class="n">BaseTask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A speech diarization task. The task will diarize the VAD speech timestamps into speakers.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_file</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">speaker_labels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initialize the speech diarization task.</span>

<span class="sd">        :param audio_file:     The audio file assigned to the task.</span>
<span class="sd">        :param speaker_labels: The speaker labels to use for the diarization. If not given, the speakers will be named</span>
<span class="sd">                               "speaker_0", "speaker_1", etc.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">audio_file</span><span class="o">=</span><span class="n">audio_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_speaker_labels</span> <span class="o">=</span> <span class="n">speaker_labels</span>

<div class="viewcode-block" id="SpeechDiarizationTask.do_task"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.SpeechDiarizationTask.do_task">[docs]</a>    <span class="k">def</span> <span class="nf">do_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">speech_timestamps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Do the task on the given speech timestamps. The task will diarize the VAD speech timestamps into speakers.</span>

<span class="sd">        :param speech_timestamps: The speech timestamps per channel to do the task on as outputted from the VAD.</span>
<span class="sd">        """</span>
        <span class="c1"># Get the speaker labels (set default if not given):</span>
        <span class="n">speaker_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_speaker_labels</span> <span class="ow">or</span> <span class="p">[</span>
            <span class="sa">f</span><span class="s2">"speaker_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">speech_timestamps</span><span class="p">))</span>
        <span class="p">]</span>

        <span class="c1"># Diarize - organize the speech timestamps into a single list of speakers and sort it by start time:</span>
        <span class="n">speech_diarization</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">speech_timestamp</span><span class="p">[</span><span class="s2">"start"</span><span class="p">],</span> <span class="n">speech_timestamp</span><span class="p">[</span><span class="s2">"end"</span><span class="p">],</span> <span class="n">speaker_label</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">speaker_label</span><span class="p">,</span> <span class="n">channel_speech_timestamps</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">speaker_labels</span><span class="p">,</span> <span class="n">speech_timestamps</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">speech_timestamp</span> <span class="ow">in</span> <span class="n">channel_speech_timestamps</span>
        <span class="p">]</span>
        <span class="n">speech_diarization</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_result</span> <span class="o">=</span> <span class="n">speech_diarization</span></div>

<div class="viewcode-block" id="SpeechDiarizationTask.to_tuple"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.SpeechDiarizationTask.to_tuple">[docs]</a>    <span class="k">def</span> <span class="nf">to_tuple</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Convert the task to a tuple to reconstruct it later (used for multiprocessing to pass in queue).</span>

<span class="sd">        :returns: The converted task.</span>
<span class="sd">        """</span>
        <span class="n">task_class</span><span class="p">,</span> <span class="n">task_kwargs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to_tuple</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">task_class</span><span class="p">,</span> <span class="p">{</span><span class="o">**</span><span class="n">task_kwargs</span><span class="p">,</span> <span class="s2">"speaker_labels"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_speaker_labels</span><span class="p">}</span></div></div>


<div class="viewcode-block" id="TaskCreator"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.TaskCreator">[docs]</a><span class="k">class</span> <span class="nc">TaskCreator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A task creator to create different tasks to run after the VAD.</span>
<span class="sd">    """</span>

    <span class="c1">#: A map from task class name to task class to use in `from_tuple`:</span>
    <span class="n">_MAP</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">BaseTask</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span> <span class="n">BaseTask</span><span class="p">,</span>
        <span class="n">SpeechDiarizationTask</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span> <span class="n">SpeechDiarizationTask</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_type</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">BaseTask</span><span class="p">],</span> <span class="n">task_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initialize the task creator.</span>
<span class="sd">        :param task_type: The task type - a `BaseTask` subclass.</span>
<span class="sd">        :param task_kwargs: Additional keyword arguments to pass to the to be created tasks.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_task_type</span> <span class="o">=</span> <span class="n">task_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_task_kwargs</span> <span class="o">=</span> <span class="n">task_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

<div class="viewcode-block" id="TaskCreator.create_task"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.TaskCreator.create_task">[docs]</a>    <span class="k">def</span> <span class="nf">create_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_file</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseTask</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Create a task with the given audio file.</span>

<span class="sd">        :param audio_file: The audio file to assign to the task.</span>

<span class="sd">        :returns: The created task.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_type</span><span class="p">(</span><span class="n">audio_file</span><span class="o">=</span><span class="n">audio_file</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_task_kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="TaskCreator.from_tuple"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.TaskCreator.from_tuple">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_tuple</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">task_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">BaseTask</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Create a task from a tuple of the audio file name and the task kwargs.</span>

<span class="sd">        :param task_tuple: The task tuple to create the task from.</span>

<span class="sd">        :returns: The created task.</span>
<span class="sd">        """</span>
        <span class="n">task_class</span><span class="p">,</span> <span class="n">task_kwargs</span> <span class="o">=</span> <span class="n">task_tuple</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_MAP</span><span class="p">[</span><span class="n">task_class</span><span class="p">](</span><span class="o">**</span><span class="n">task_kwargs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="VoiceActivityDetector"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.VoiceActivityDetector">[docs]</a><span class="k">class</span> <span class="nc">VoiceActivityDetector</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A voice activity detection wrapper for the silero VAD model - https://github.com/snakers4/silero-vad.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="c1"># Model loading kwargs:</span>
        <span class="n">use_onnx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">force_onnx_cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="c1"># Detection kwargs:</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">sampling_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16_000</span><span class="p">,</span>
        <span class="n">min_speech_duration_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span>
        <span class="n">max_speech_duration_s</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">),</span>
        <span class="n">min_silence_duration_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">window_size_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
        <span class="n">speech_pad_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">return_seconds</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">per_channel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initialize the voice activity detector.</span>

<span class="sd">        :param use_onnx:                Whether to use ONNX for inference. Default is True.</span>
<span class="sd">        :param force_onnx_cpu:          Whether to force ONNX to use CPU for inference. Default is True.</span>
<span class="sd">        :param threshold:               Speech threshold. Silero VAD outputs speech probabilities for each audio chunk,</span>
<span class="sd">                                        probabilities ABOVE this value are considered as SPEECH. It is better to tune</span>
<span class="sd">                                        this parameter for each dataset separately, but "lazy" 0.5 is pretty good for</span>
<span class="sd">                                        most datasets.</span>
<span class="sd">        :param sampling_rate:           Currently, silero VAD models support 8000 and 16000 sample rates.</span>
<span class="sd">        :param min_speech_duration_ms:  Final speech chunks shorter min_speech_duration_ms are thrown out.</span>
<span class="sd">        :param max_speech_duration_s:   Maximum duration of speech chunks in seconds. Chunks longer than</span>
<span class="sd">                                        `max_speech_duration_s` will be split at the timestamp of the last silence that</span>
<span class="sd">                                        lasts more than 100ms (if any), to prevent aggressive cutting. Otherwise,</span>
<span class="sd">                                        they will be split aggressively just before max_speech_duration_s.</span>
<span class="sd">        :param min_silence_duration_ms: In the end of each speech chunk wait for min_silence_duration_ms before</span>
<span class="sd">                                        separating it.</span>
<span class="sd">        :param window_size_samples:     Audio chunks of window_size_samples size are fed to the silero VAD model.</span>
<span class="sd">                                        WARNING! Silero VAD models were trained using 512, 1024, 1536 samples for 16000</span>
<span class="sd">                                        sample rate and 256, 512, 768 samples for 8000 sample rate. Values other than</span>
<span class="sd">                                        these may affect model performance!</span>
<span class="sd">        :param speech_pad_ms:           Final speech chunks are padded by speech_pad_ms each side.</span>
<span class="sd">        :param return_seconds:          Whether return timestamps in seconds. False means to return timestamps in</span>
<span class="sd">                                        samples (default - False).</span>
<span class="sd">        :param per_channel:             Whether to return timestamps per channel (default - False). This will run VAD</span>
<span class="sd">                                        on each channel separately and return a list of timestamps per channel.</span>
<span class="sd">        """</span>
        <span class="c1"># Store configurations:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_onnx</span> <span class="o">=</span> <span class="n">use_onnx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_force_onnx_cpu</span> <span class="o">=</span> <span class="n">force_onnx_cpu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sampling_rate</span> <span class="o">=</span> <span class="n">sampling_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_min_speech_duration_ms</span> <span class="o">=</span> <span class="n">min_speech_duration_ms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_speech_duration_s</span> <span class="o">=</span> <span class="n">max_speech_duration_s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_min_silence_duration_ms</span> <span class="o">=</span> <span class="n">min_silence_duration_ms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_window_size_samples</span> <span class="o">=</span> <span class="n">window_size_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_speech_pad_ms</span> <span class="o">=</span> <span class="n">speech_pad_ms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_return_seconds</span> <span class="o">=</span> <span class="n">return_seconds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_channel</span> <span class="o">=</span> <span class="n">per_channel</span>

        <span class="c1"># Prepare the model variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_speech_timestamps</span><span class="p">:</span> <span class="n">FunctionType</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="VoiceActivityDetector.load"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.VoiceActivityDetector.load">[docs]</a>    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">force_reload</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Load the VAD model.</span>

<span class="sd">        :param force_reload: Whether to force reload the model even if it was already loaded. Default is True.</span>
<span class="sd">        """</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">utils</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">repo_or_dir</span><span class="o">=</span><span class="s2">"snakers4/silero-vad"</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">"silero_vad"</span><span class="p">,</span>
            <span class="n">force_reload</span><span class="o">=</span><span class="n">force_reload</span><span class="p">,</span>
            <span class="n">onnx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_onnx</span><span class="p">,</span>
            <span class="n">force_onnx_cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_force_onnx_cpu</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_speech_timestamps</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>  <span class="c1"># save_audio,</span>
            <span class="n">_</span><span class="p">,</span>  <span class="c1"># read_audio,</span>
            <span class="n">_</span><span class="p">,</span>  <span class="c1"># VADIterator,</span>
            <span class="n">_</span><span class="p">,</span>  <span class="c1"># collect_chunks</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">utils</span></div>

<div class="viewcode-block" id="VoiceActivityDetector.detect_voice"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.VoiceActivityDetector.detect_voice">[docs]</a>    <span class="k">def</span> <span class="nf">detect_voice</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">audio_file</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Infer the audio through the VAD model and return the speech timestamps.</span>

<span class="sd">        :param audio_file: The audio file to infer.</span>

<span class="sd">        :returns: The speech timestamps in the audio. A list of timestamps where each timestamp is a dictionary with the</span>
<span class="sd">                 following keys:</span>

<span class="sd">                 * "start": The start sample index of the speech in the audio.</span>
<span class="sd">                 * "end":   The end sample index of the speech in the audio.</span>

<span class="sd">                 If `per_channel` is True, a list of timestamps per channel will be returned.</span>
<span class="sd">        """</span>
        <span class="c1"># Cast to a numpy array:</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_audio</span><span class="p">(</span><span class="n">audio_file</span><span class="p">)</span>

        <span class="c1"># Detect speech:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_channel</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_speech_timestamps</span><span class="p">(</span>
                <span class="n">audio</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_threshold</span><span class="p">,</span>
                <span class="n">min_speech_duration_ms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_min_speech_duration_ms</span><span class="p">,</span>
                <span class="n">max_speech_duration_s</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_speech_duration_s</span><span class="p">,</span>
                <span class="n">min_silence_duration_ms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_min_silence_duration_ms</span><span class="p">,</span>
                <span class="n">speech_pad_ms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_speech_pad_ms</span><span class="p">,</span>
                <span class="n">sampling_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sampling_rate</span><span class="p">,</span>
                <span class="n">window_size_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_window_size_samples</span><span class="p">,</span>
                <span class="n">return_seconds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_return_seconds</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Per channel:</span>
        <span class="n">speech_timestamps</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="n">audio</span><span class="p">:</span>
            <span class="n">speech_timestamps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_get_speech_timestamps</span><span class="p">(</span>
                    <span class="n">channel</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span>
                    <span class="n">threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_threshold</span><span class="p">,</span>
                    <span class="n">min_speech_duration_ms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_min_speech_duration_ms</span><span class="p">,</span>
                    <span class="n">max_speech_duration_s</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_speech_duration_s</span><span class="p">,</span>
                    <span class="n">min_silence_duration_ms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_min_silence_duration_ms</span><span class="p">,</span>
                    <span class="n">speech_pad_ms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_speech_pad_ms</span><span class="p">,</span>
                    <span class="n">sampling_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sampling_rate</span><span class="p">,</span>
                    <span class="n">window_size_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_window_size_samples</span><span class="p">,</span>
                    <span class="n">return_seconds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_return_seconds</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">speech_timestamps</span></div>

    <span class="k">def</span> <span class="nf">_read_audio</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Read the audio from the given path and return it as a tensor.</span>

<span class="sd">        :param path: The path to the audio file.</span>

<span class="sd">        :returns: The audio as a tensor.</span>
<span class="sd">        """</span>
        <span class="c1"># Read the audio:</span>
        <span class="n">audio</span><span class="p">,</span> <span class="n">sampling_rate</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

        <span class="c1"># Check if the audio is stereo and if so, convert it to mono (only if not per channel):</span>
        <span class="k">if</span> <span class="n">audio</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_channel</span><span class="p">:</span>
            <span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Resample the audio if needed:</span>
        <span class="k">if</span> <span class="n">sampling_rate</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sampling_rate</span><span class="p">:</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resample</span><span class="p">(</span>
                <span class="n">orig_freq</span><span class="o">=</span><span class="n">sampling_rate</span><span class="p">,</span> <span class="n">new_freq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_sampling_rate</span>
            <span class="p">)</span>
            <span class="n">audio</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>

        <span class="c1"># Return the audio (squeeze if not per channel):</span>
        <span class="k">return</span> <span class="n">audio</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_channel</span> <span class="k">else</span> <span class="n">audio</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></div>


<span class="c1">#: The value to send into multiprocessing queues to stop the process:</span>
<span class="n">_MULTIPROCESSING_STOP_MARK</span> <span class="o">=</span> <span class="s2">"STOP"</span>


<span class="k">def</span> <span class="nf">_multiprocessing_complete_tasks</span><span class="p">(</span>
    <span class="n">vad_init_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">tasks_queue</span><span class="p">:</span> <span class="n">Queue</span><span class="p">,</span> <span class="n">results_queue</span><span class="p">:</span> <span class="n">Queue</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Complete the tasks in the given queue and put the results in the given results queue. The function will stop when</span>
<span class="sd">    the given tasks queue will receive the stop mark. It is aimed to be used with multiprocessing as a process.</span>

<span class="sd">    :param vad_init_kwargs: The VAD initialization kwargs.</span>
<span class="sd">    :param tasks_queue:     A queue to get the tasks from.</span>
<span class="sd">    :param results_queue:   A queue to put the results in.</span>
<span class="sd">    """</span>
    <span class="c1"># Initialize and load the VAD:</span>
    <span class="n">vad</span> <span class="o">=</span> <span class="n">VoiceActivityDetector</span><span class="p">(</span><span class="o">**</span><span class="n">vad_init_kwargs</span><span class="p">)</span>
    <span class="n">vad</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">force_reload</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Start listening to the tasks queue:</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Get the task:</span>
        <span class="n">task</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">tasks_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="n">_MULTIPROCESSING_STOP_MARK</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Create the task:</span>
            <span class="n">task</span> <span class="o">=</span> <span class="n">TaskCreator</span><span class="o">.</span><span class="n">from_tuple</span><span class="p">(</span><span class="n">task_tuple</span><span class="o">=</span><span class="n">task</span><span class="p">)</span>
            <span class="c1"># Run the file through the VAD:</span>
            <span class="n">speech_timestamps</span> <span class="o">=</span> <span class="n">vad</span><span class="o">.</span><span class="n">detect_voice</span><span class="p">(</span><span class="n">audio_file</span><span class="o">=</span><span class="n">task</span><span class="o">.</span><span class="n">audio_file</span><span class="p">)</span>
            <span class="c1"># Complete the task:</span>
            <span class="n">task</span><span class="o">.</span><span class="n">do_task</span><span class="p">(</span><span class="n">speech_timestamps</span><span class="o">=</span><span class="n">speech_timestamps</span><span class="p">)</span>
            <span class="c1"># Build the result:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">get_result</span><span class="p">())</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exception</span><span class="p">:</span>
            <span class="c1"># Build the error:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">audio_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">exception</span><span class="p">)))</span>
        <span class="c1"># Collect the result / error:</span>
        <span class="n">results_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="c1"># Mark the end of the tasks:</span>
    <span class="n">results_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">_MULTIPROCESSING_STOP_MARK</span><span class="p">)</span>


<span class="c1"># Get the global logger:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">mlrun</span>

    <span class="n">_LOGGER</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">get_or_create_ctx</span><span class="p">(</span><span class="s2">"silero_vad"</span><span class="p">)</span><span class="o">.</span><span class="n">logger</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="n">_LOGGER</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>


<div class="viewcode-block" id="detect_voice"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.detect_voice">[docs]</a><span class="k">def</span> <span class="nf">detect_voice</span><span class="p">(</span>
    <span class="c1"># Input kwargs:</span>
    <span class="n">data_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]],</span>
    <span class="c1"># Model loading kwargs:</span>
    <span class="n">use_onnx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">force_onnx_cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># Detection kwargs:</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">sampling_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16_000</span><span class="p">,</span>
    <span class="n">min_speech_duration_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span>
    <span class="n">max_speech_duration_s</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">),</span>
    <span class="n">min_silence_duration_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">window_size_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">speech_pad_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">return_seconds</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">per_channel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Other kwargs:</span>
    <span class="n">use_multiprocessing</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Perform voice activity detection on given audio files using the silero VAD model -</span>
<span class="sd">    https://github.com/snakers4/silero-vad. The end result is a dictionary with the file names as keys and their</span>
<span class="sd">    VAD timestamps dictionaries as value.</span>

<span class="sd">    For example::</span>

<span class="sd">        {</span>
<span class="sd">            "file_1.wav": [</span>
<span class="sd">                {"start": 0, "end": 16000},</span>
<span class="sd">                {"start": 16000, "end": 32000},</span>
<span class="sd">                {"start": 32000, "end": 48000},</span>
<span class="sd">                ...</span>
<span class="sd">            ],</span>
<span class="sd">            "file_2.wav": [</span>
<span class="sd">                {"start": 0, "end": 16000},</span>
<span class="sd">                {"start": 16000, "end": 32000},</span>
<span class="sd">                {"start": 32000, "end": 48000},</span>
<span class="sd">                ...</span>
<span class="sd">            ],</span>
<span class="sd">            ...</span>
<span class="sd">        }</span>


<span class="sd">    :param data_path:               The path to the audio files to diarize. Can be a path to a single file, a path to a</span>
<span class="sd">                                    directory or a list of paths to files.</span>
<span class="sd">    :param use_onnx:                Whether to use ONNX for inference. Default is True.</span>
<span class="sd">    :param force_onnx_cpu:          Whether to force ONNX to use CPU for inference. Default is True.</span>
<span class="sd">    :param threshold:               Speech threshold. Silero VAD outputs speech probabilities for each audio chunk,</span>
<span class="sd">                                    probabilities ABOVE this value are considered as SPEECH. It is better to tune</span>
<span class="sd">                                    this parameter for each dataset separately, but "lazy" 0.5 is pretty good for</span>
<span class="sd">                                    most datasets.</span>
<span class="sd">    :param sampling_rate:           Currently, silero VAD models support 8000 and 16000 sample rates.</span>
<span class="sd">    :param min_speech_duration_ms:  Final speech chunks shorter min_speech_duration_ms are thrown out.</span>
<span class="sd">    :param max_speech_duration_s:   Maximum duration of speech chunks in seconds. Chunks longer than</span>
<span class="sd">                                    `max_speech_duration_s` will be split at the timestamp of the last silence that</span>
<span class="sd">                                    lasts more than 100ms (if any), to prevent aggressive cutting. Otherwise, they will</span>
<span class="sd">                                    be split aggressively just before max_speech_duration_s.</span>
<span class="sd">    :param min_silence_duration_ms: In the end of each speech chunk wait for min_silence_duration_ms before separating</span>
<span class="sd">                                    it.</span>
<span class="sd">    :param window_size_samples:     Audio chunks of window_size_samples size are fed to the silero VAD model.</span>

<span class="sd">                                    WARNING! Silero VAD models were trained using 512, 1024, 1536 samples for 16000</span>
<span class="sd">                                    sample rate and 256, 512, 768 samples for 8000 sample rate. Values other than</span>
<span class="sd">                                    these may affect model performance!</span>
<span class="sd">    :param speech_pad_ms:           Final speech chunks are padded by speech_pad_ms each side.</span>
<span class="sd">    :param return_seconds:          Whether return timestamps in seconds. False means to return timestamps in samples</span>
<span class="sd">                                    (default - False).</span>
<span class="sd">    :param per_channel:             Whether to return timestamps per channel (default - False). This will run VAD on</span>
<span class="sd">                                    each channel separately and return a list of timestamps per channel.</span>
<span class="sd">    :param use_multiprocessing:     The number of workers to use for multiprocessing. If 0, no multiprocessing will</span>
<span class="sd">                                    be used. Default is 0.</span>
<span class="sd">    :param verbose:                 Verbosity.</span>
<span class="sd">    """</span>
    <span class="k">global</span> <span class="n">_LOGGER</span>

    <span class="c1"># Get the input audio files to transcribe:</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Collecting audio files."</span><span class="p">)</span>
    <span class="n">audio_files</span> <span class="o">=</span> <span class="n">_get_audio_files</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="n">data_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Collected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">)</span><span class="si">}</span><span class="s2"> audio files."</span><span class="p">)</span>

    <span class="c1"># Initialize the transcription pipeline:</span>
    <span class="n">vad_init_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"use_onnx"</span><span class="p">:</span> <span class="n">use_onnx</span><span class="p">,</span>
        <span class="s2">"force_onnx_cpu"</span><span class="p">:</span> <span class="n">force_onnx_cpu</span><span class="p">,</span>
        <span class="s2">"threshold"</span><span class="p">:</span> <span class="n">threshold</span><span class="p">,</span>
        <span class="s2">"sampling_rate"</span><span class="p">:</span> <span class="n">sampling_rate</span><span class="p">,</span>
        <span class="s2">"min_speech_duration_ms"</span><span class="p">:</span> <span class="n">min_speech_duration_ms</span><span class="p">,</span>
        <span class="s2">"max_speech_duration_s"</span><span class="p">:</span> <span class="n">max_speech_duration_s</span><span class="p">,</span>
        <span class="s2">"min_silence_duration_ms"</span><span class="p">:</span> <span class="n">min_silence_duration_ms</span><span class="p">,</span>
        <span class="s2">"window_size_samples"</span><span class="p">:</span> <span class="n">window_size_samples</span><span class="p">,</span>
        <span class="s2">"speech_pad_ms"</span><span class="p">:</span> <span class="n">speech_pad_ms</span><span class="p">,</span>
        <span class="s2">"return_seconds"</span><span class="p">:</span> <span class="n">return_seconds</span><span class="p">,</span>
        <span class="s2">"per_channel"</span><span class="p">:</span> <span class="n">per_channel</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># Create the task creator:</span>
    <span class="n">task_creator</span> <span class="o">=</span> <span class="n">TaskCreator</span><span class="p">(</span><span class="n">task_type</span><span class="o">=</span><span class="n">BaseTask</span><span class="p">)</span>

    <span class="c1"># Run the transcription:</span>
    <span class="k">if</span> <span class="n">use_multiprocessing</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">_parallel_run</span><span class="p">(</span>
            <span class="n">n_workers</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>
            <span class="n">audio_files</span><span class="o">=</span><span class="n">audio_files</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">"Detecting voice"</span><span class="p">,</span>
            <span class="n">vad_init_kwargs</span><span class="o">=</span><span class="n">vad_init_kwargs</span><span class="p">,</span>
            <span class="n">task_creator</span><span class="o">=</span><span class="n">task_creator</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">_run</span><span class="p">(</span>
            <span class="n">audio_files</span><span class="o">=</span><span class="n">audio_files</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">"Detecting voice"</span><span class="p">,</span>
            <span class="n">vad_init_kwargs</span><span class="o">=</span><span class="n">vad_init_kwargs</span><span class="p">,</span>
            <span class="n">task_creator</span><span class="o">=</span><span class="n">task_creator</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Process the results:</span>
    <span class="k">return</span> <span class="n">_process_results</span><span class="p">(</span><span class="n">results</span><span class="o">=</span><span class="n">results</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span></div>


<div class="viewcode-block" id="diarize"><a class="viewcode-back" href="documentation.html#silero_vad.silero_vad.diarize">[docs]</a><span class="k">def</span> <span class="nf">diarize</span><span class="p">(</span>
    <span class="c1"># Input / Output kwargs:</span>
    <span class="n">data_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]],</span>
    <span class="c1"># Model loading kwargs:</span>
    <span class="n">use_onnx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">force_onnx_cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># Detection kwargs:</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">sampling_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16_000</span><span class="p">,</span>
    <span class="n">min_speech_duration_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span>
    <span class="n">max_speech_duration_s</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">),</span>
    <span class="n">min_silence_duration_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">window_size_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">speech_pad_ms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="c1"># Diarization kwargs:</span>
    <span class="n">speaker_labels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># Other kwargs:</span>
    <span class="n">use_multiprocessing</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Perform speech diarization on given audio files using the silero VAD model - https://github.com/snakers4/silero-vad.</span>
<span class="sd">    The speech diarization is performed per channel so that each channel in the audio belong to a different speaker. The</span>
<span class="sd">    end result is a dictionary with the file names as keys and their diarization as value. A diarization is a list</span>
<span class="sd">    of tuples: (start, end, speaker_label).</span>

<span class="sd">    For example::</span>

<span class="sd">        {</span>
<span class="sd">            "file_1.wav": [</span>
<span class="sd">                (0.0, 1.0, "speaker_0"),</span>
<span class="sd">                (1.0, 2.0, "speaker_1"),</span>
<span class="sd">                (2.0, 3.0, "speaker_0"),</span>
<span class="sd">                ...</span>
<span class="sd">            ],</span>
<span class="sd">            "file_2.wav": [</span>
<span class="sd">                (0.0, 1.0, "speaker_0"),</span>
<span class="sd">                (1.0, 2.0, "speaker_1"),</span>
<span class="sd">                (2.0, 3.0, "speaker_0"),</span>
<span class="sd">                ...</span>
<span class="sd">            ],</span>
<span class="sd">            ...</span>
<span class="sd">        }</span>


<span class="sd">    :param data_path:               The path to the audio files to diarize. Can be a path to a single file, a path to a</span>
<span class="sd">                                    directory or a list of paths to files.</span>
<span class="sd">    :param use_onnx:                Whether to use ONNX for inference. Default is True.</span>
<span class="sd">    :param force_onnx_cpu:          Whether to force ONNX to use CPU for inference. Default is True.</span>
<span class="sd">    :param threshold:               Speech threshold. Silero VAD outputs speech probabilities for each audio chunk,</span>
<span class="sd">                                    probabilities ABOVE this value are considered as SPEECH. It is better to tune</span>
<span class="sd">                                    this parameter for each dataset separately, but "lazy" 0.5 is pretty good for</span>
<span class="sd">                                    most datasets.</span>
<span class="sd">    :param sampling_rate:           Currently, silero VAD models support 8000 and 16000 sample rates.</span>
<span class="sd">    :param min_speech_duration_ms:  Final speech chunks shorter min_speech_duration_ms are thrown out.</span>
<span class="sd">    :param max_speech_duration_s:   Maximum duration of speech chunks in seconds. Chunks longer than</span>
<span class="sd">                                    `max_speech_duration_s` will be split at the timestamp of the last silence that</span>
<span class="sd">                                    lasts more than 100ms (if any), to prevent aggressive cutting. Otherwise, they will</span>
<span class="sd">                                    be split aggressively just before max_speech_duration_s.</span>
<span class="sd">    :param min_silence_duration_ms: In the end of each speech chunk wait for min_silence_duration_ms before separating</span>
<span class="sd">                                    it.</span>
<span class="sd">    :param window_size_samples:     Audio chunks of window_size_samples size are fed to the silero VAD model.</span>

<span class="sd">                                    WARNING! Silero VAD models were trained using 512, 1024, 1536 samples for 16000</span>
<span class="sd">                                    sample rate and 256, 512, 768 samples for 8000 sample rate. Values other than</span>
<span class="sd">                                    these may affect model performance!</span>
<span class="sd">    :param speech_pad_ms:           Final speech chunks are padded by speech_pad_ms each side.</span>
<span class="sd">    :param speaker_labels:          The speaker labels to use for the diarization. If not given, the speakers will be</span>
<span class="sd">                                    named "speaker_0", "speaker_1", etc.</span>
<span class="sd">    :param use_multiprocessing:     The number of workers to use for multiprocessing. If 0, no multiprocessing will</span>
<span class="sd">                                    be used. Default is 0.</span>
<span class="sd">    :param verbose:                 Verbosity.</span>
<span class="sd">    """</span>
    <span class="k">global</span> <span class="n">_LOGGER</span>

    <span class="c1"># Get the input audio files to transcribe:</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Collecting audio files."</span><span class="p">)</span>
    <span class="n">audio_files</span> <span class="o">=</span> <span class="n">_get_audio_files</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="n">data_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Collected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">)</span><span class="si">}</span><span class="s2"> audio files."</span><span class="p">)</span>

    <span class="c1"># Initialize the transcription pipeline:</span>
    <span class="n">vad_init_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"use_onnx"</span><span class="p">:</span> <span class="n">use_onnx</span><span class="p">,</span>
        <span class="s2">"force_onnx_cpu"</span><span class="p">:</span> <span class="n">force_onnx_cpu</span><span class="p">,</span>
        <span class="s2">"threshold"</span><span class="p">:</span> <span class="n">threshold</span><span class="p">,</span>
        <span class="s2">"sampling_rate"</span><span class="p">:</span> <span class="n">sampling_rate</span><span class="p">,</span>
        <span class="s2">"min_speech_duration_ms"</span><span class="p">:</span> <span class="n">min_speech_duration_ms</span><span class="p">,</span>
        <span class="s2">"max_speech_duration_s"</span><span class="p">:</span> <span class="n">max_speech_duration_s</span><span class="p">,</span>
        <span class="s2">"min_silence_duration_ms"</span><span class="p">:</span> <span class="n">min_silence_duration_ms</span><span class="p">,</span>
        <span class="s2">"window_size_samples"</span><span class="p">:</span> <span class="n">window_size_samples</span><span class="p">,</span>
        <span class="s2">"speech_pad_ms"</span><span class="p">:</span> <span class="n">speech_pad_ms</span><span class="p">,</span>
        <span class="s2">"return_seconds"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">"per_channel"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># Create the task creator:</span>
    <span class="n">task_creator</span> <span class="o">=</span> <span class="n">TaskCreator</span><span class="p">(</span>
        <span class="n">task_type</span><span class="o">=</span><span class="n">SpeechDiarizationTask</span><span class="p">,</span> <span class="n">task_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">"speaker_labels"</span><span class="p">:</span> <span class="n">speaker_labels</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Run the transcription:</span>
    <span class="k">if</span> <span class="n">use_multiprocessing</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">_parallel_run</span><span class="p">(</span>
            <span class="n">n_workers</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>
            <span class="n">audio_files</span><span class="o">=</span><span class="n">audio_files</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">"Diarizing"</span><span class="p">,</span>
            <span class="n">vad_init_kwargs</span><span class="o">=</span><span class="n">vad_init_kwargs</span><span class="p">,</span>
            <span class="n">task_creator</span><span class="o">=</span><span class="n">task_creator</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">_run</span><span class="p">(</span>
            <span class="n">audio_files</span><span class="o">=</span><span class="n">audio_files</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">"Diarizing"</span><span class="p">,</span>
            <span class="n">vad_init_kwargs</span><span class="o">=</span><span class="n">vad_init_kwargs</span><span class="p">,</span>
            <span class="n">task_creator</span><span class="o">=</span><span class="n">task_creator</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Process the results:</span>
    <span class="k">return</span> <span class="n">_process_results</span><span class="p">(</span><span class="n">results</span><span class="o">=</span><span class="n">results</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_audio_files</span><span class="p">(</span>
    <span class="n">data_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Path</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Get the audio files from the data path. If a path to a directory is given, all files in the directory will be</span>
<span class="sd">    collected.</span>

<span class="sd">    :param data_path: The data path to collect the audio files from.</span>

<span class="sd">    :returns: The audio files list.</span>
<span class="sd">    """</span>
    <span class="c1"># Check if given a list of paths:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">audio_files</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">data_path</span><span class="p">:</span>
            <span class="n">audio_files</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_get_audio_files</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="n">path</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">audio_files</span>

    <span class="c1"># Check if given a single string path to cast it to a `pathlib.Path`:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">data_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>

    <span class="c1"># Check if the path is of a directory or a file:</span>
    <span class="k">if</span> <span class="n">data_path</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
        <span class="c1"># Get all files inside the directory:</span>
        <span class="n">audio_files</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data_path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">"*.*"</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">data_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
        <span class="n">audio_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_path</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Unrecognized data path. The parameter `data_path` must be a valid path to either a directory path or a "</span>
            <span class="sa">f</span><span class="s2">"file. Given: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span><span class="si">}</span><span class="s2"> "</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">audio_files</span>


<span class="k">def</span> <span class="nf">_run</span><span class="p">(</span>
    <span class="n">audio_files</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Path</span><span class="p">],</span>
    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">vad_init_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">task_creator</span><span class="p">:</span> <span class="n">TaskCreator</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Load a VAD and use it to complete the tasks that will be created on the provided files using the given task creator.</span>

<span class="sd">    :param audio_files:     The audio files to use.</span>
<span class="sd">    :param description:     The description to use for the progress bar.</span>
<span class="sd">    :param vad_init_kwargs: The VAD initialization keyword arguments.</span>
<span class="sd">    :param task_creator:    The task creator to use to create the tasks.</span>
<span class="sd">    :param verbose:         Verbosity.</span>

<span class="sd">    :returns: The collected results.</span>
<span class="sd">    """</span>
    <span class="c1"># Load the VAD:</span>
    <span class="n">vad</span> <span class="o">=</span> <span class="n">VoiceActivityDetector</span><span class="p">(</span><span class="o">**</span><span class="n">vad_init_kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loading the VAD model."</span><span class="p">)</span>
    <span class="n">vad</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"VAD model loaded."</span><span class="p">)</span>

    <span class="c1"># Run the VAD on the audio files and collect the results:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">audio_file</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
        <span class="n">audio_files</span><span class="p">,</span>
        <span class="n">desc</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
        <span class="n">unit</span><span class="o">=</span><span class="s2">"file"</span><span class="p">,</span>
        <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">),</span>
        <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Create the task:</span>
            <span class="n">task</span> <span class="o">=</span> <span class="n">task_creator</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">audio_file</span><span class="o">=</span><span class="n">audio_file</span><span class="p">)</span>
            <span class="c1"># Run the file through the VAD:</span>
            <span class="n">speech_timestamps</span> <span class="o">=</span> <span class="n">vad</span><span class="o">.</span><span class="n">detect_voice</span><span class="p">(</span><span class="n">audio_file</span><span class="o">=</span><span class="n">audio_file</span><span class="p">)</span>
            <span class="c1"># Complete the task:</span>
            <span class="n">task</span><span class="o">.</span><span class="n">do_task</span><span class="p">(</span><span class="n">speech_timestamps</span><span class="o">=</span><span class="n">speech_timestamps</span><span class="p">)</span>
            <span class="c1"># Collect the result:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="kc">False</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">get_result</span><span class="p">()))</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exception</span><span class="p">:</span>
            <span class="c1"># Collect the error:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="kc">True</span><span class="p">,</span> <span class="p">(</span><span class="n">audio_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">exception</span><span class="p">))))</span>

    <span class="k">return</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">_parallel_run</span><span class="p">(</span>
    <span class="n">n_workers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">audio_files</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Path</span><span class="p">],</span>
    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">vad_init_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">task_creator</span><span class="p">:</span> <span class="n">TaskCreator</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Run multiple VAD workers with multiprocessing to complete the tasks that will be created on the provided files using</span>
<span class="sd">    the given task creator.</span>

<span class="sd">    :param n_workers:       The number of workers to use.</span>
<span class="sd">    :param audio_files:     The audio files to use.</span>
<span class="sd">    :param description:     The description to use for the progress bar.</span>
<span class="sd">    :param vad_init_kwargs: The VAD initialization keyword arguments.</span>
<span class="sd">    :param task_creator:    The task creator to use to create the tasks.</span>
<span class="sd">    :param verbose:         Verbosity.</span>

<span class="sd">    :returns: The collected results.</span>
<span class="sd">    """</span>
    <span class="c1"># Load the VAD (download once, and it will be loaded then per process later on):</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loading the VAD model."</span><span class="p">)</span>
    <span class="n">vad</span> <span class="o">=</span> <span class="n">VoiceActivityDetector</span><span class="p">(</span><span class="o">**</span><span class="n">vad_init_kwargs</span><span class="p">)</span>
    <span class="n">vad</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"VAD model loaded."</span><span class="p">)</span>

    <span class="c1"># Check the number of workers:</span>
    <span class="k">if</span> <span class="n">n_workers</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">):</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"The number of workers (</span><span class="si">{</span><span class="n">n_workers</span><span class="si">}</span><span class="s2">) is larger than the number of audio files (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">)</span><span class="si">}</span><span class="s2">). "</span>
            <span class="sa">f</span><span class="s2">"Setting the number of workers to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">)</span><span class="si">}</span><span class="s2">."</span>
        <span class="p">)</span>
        <span class="n">n_workers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">)</span>

    <span class="c1"># Initialize the multiprocessing queues:</span>
    <span class="n">tasks_queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
    <span class="n">results_queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>

    <span class="c1"># Initialize the multiprocessing processes:</span>
    <span class="n">task_completion_processes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">Process</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="n">_multiprocessing_complete_tasks</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">"vad_init_kwargs"</span><span class="p">:</span> <span class="n">vad_init_kwargs</span><span class="p">,</span>
                <span class="s2">"tasks_queue"</span><span class="p">:</span> <span class="n">tasks_queue</span><span class="p">,</span>
                <span class="s2">"results_queue"</span><span class="p">:</span> <span class="n">results_queue</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_workers</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Start the multiprocessing processes:</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">task_completion_processes</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="c1"># Put the tasks in the queue:</span>
    <span class="k">for</span> <span class="n">audio_file</span> <span class="ow">in</span> <span class="n">audio_files</span><span class="p">:</span>
        <span class="n">tasks_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">task_creator</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">audio_file</span><span class="o">=</span><span class="n">audio_file</span><span class="p">)</span><span class="o">.</span><span class="n">to_tuple</span><span class="p">())</span>

    <span class="c1"># Put the stop marks in the queue:</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_workers</span><span class="p">):</span>
        <span class="n">tasks_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">_MULTIPROCESSING_STOP_MARK</span><span class="p">)</span>

    <span class="c1"># Collect the results:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">stop_marks_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span>
        <span class="n">desc</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
        <span class="n">unit</span><span class="o">=</span><span class="s2">"file"</span><span class="p">,</span>
        <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">),</span>
        <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">,</span>
    <span class="p">)</span> <span class="k">as</span> <span class="n">progressbar</span><span class="p">:</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># Get a result from the queue:</span>
            <span class="n">result</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="n">results_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">result</span> <span class="o">==</span> <span class="n">_MULTIPROCESSING_STOP_MARK</span><span class="p">:</span>
                <span class="n">stop_marks_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">stop_marks_counter</span> <span class="o">==</span> <span class="n">n_workers</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Collect the result:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
                <span class="n">progressbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Wait for the processes to finish:</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">task_completion_processes</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">_process_results</span><span class="p">(</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]],</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Process the results of the tasks.</span>

<span class="sd">    :param results: The results to process.</span>
<span class="sd">    :param verbose: Verbosity.</span>

<span class="sd">    :returns: The processed results as a tuple of successes and errors.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Summarizing the results."</span><span class="p">)</span>
    <span class="n">successes</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">is_error</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_error</span><span class="p">:</span>
            <span class="n">errors</span><span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">successes</span><span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Done (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">successes</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">successes</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">successes</span><span class="p">,</span> <span class="n">errors</span>
</pre></div>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
      © Copyright .<br/>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>